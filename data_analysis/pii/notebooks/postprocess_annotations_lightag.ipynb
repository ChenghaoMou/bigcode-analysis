{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LighTag data post-processing\n",
    "Let's download the dataset from LightTag using their API and postprocess the data + push it to the hub (downloading from the LightTag's UI doesn't work properly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "LIGHTTAG_DOMAIN = 'demo'  #should be your lighttag domain\n",
    "domain = \"bigcodepii\"\n",
    "SERVER = f'https://{domain}.lighttag.io/api/'\n",
    "API_BASE = SERVER +'v1/'\n",
    "MY_USER=\"XX\"\n",
    "MY_PWD=\"XX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(SERVER+'auth/token/login/',\n",
    "              json={\"username\":MY_USER,\"password\":MY_PWD})\n",
    "assert response.status_code ==200, \"Couldn't authenticate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_details = response.json()\n",
    "token = auth_details['key']\n",
    "assert auth_details['is_manager'] ==1, \"not a manager\" # Check you are a manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '87c47b2c-d503-4967-b314-c04d1e7f8be7',\n",
       "  'slug': 'default',\n",
       "  'url': 'http://bigcodepii.lighttag.io/api/v1/projects/default/',\n",
       "  'name': 'default'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = requests.session()\n",
    "session.headers.update({\"Authorization\":\"Token {token}\".format(token=token)})\n",
    "#Try it out\n",
    "session.get(API_BASE+'projects/').json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'a6e0c132-cd58-45d1-8dd5-5af8cdc6d399',\n",
       " 'name': 'PII labeling pre-filtered data',\n",
       " 'slug': 'pii-labeling-pre-filtered-data',\n",
       " 'url': 'http://bigcodepii.lighttag.io/api/v1/projects/default/task_definitions/pii-labeling-pre-filtered-data/',\n",
       " 'allow_suggestions': True,\n",
       " 'annotators_per_example': 1,\n",
       " 'async_status': 'done',\n",
       " 'archived': False,\n",
       " 'priority': 1,\n",
       " 'active': True,\n",
       " 'guidelines': '## Task Overview\\n\\nWelcome to our annotation task. In this task we\\'ll present you with one code file at a time and ask you to tag specific entities. We\\'ll be using this data to evaluate PII detection tools on source code from different programming languages.   \\n\\n1. Please highlight the entire span for each tags where applicable. For example: For tag `NAME`, if the text presented has John Doe, please highlight John Doe as one span, instead of highlighting John and Doe separately.\\n2. If you think a word that should be highlighted, but unsure about which tag to go to, use `AMBIGUOUS` instead.\\n3. **Do not overlap** tags. Tag the one most applicable to the entire span. For example, if a person\\'s name is part of `EMAIL`, do not tag `NAME`.\\n\\n## Tags Guidelines\\n\\nFor each file, please highlight you find any corresponding to the following tags: \\n\\n### API_KEY\\n\\nIncluding API Keys or API Tokens, Bearer Tokens, OAuth Tokens, see [here](https://www.freecodecamp.org/news/best-practices-for-building-api-keys-97c26eabfea9/#:~:text=the%20right%20way.-,API%20Key%20Generation,-Since%20the%20API) for example. Please highlight only the actual key.\\n\\n### AMBIGUOUS\\n\\nIf unsure whether to highlight a text, or which tag to highlight a text for, tag as `AMBIGUOUS` to allow reviewers to take a look later.\\n\\n### EMAIL\\n\\nEmail address, including generic emails such as support@organization.com.\\n\\n### IP_ADDRESS\\n\\nIP addresses could come in two different formats, see [IPv4 and IPv6 address formats](https://www.ibm.com/docs/en/ts3500-tape-library?topic=functionality-ipv4-ipv6-address-formats). Please tag both formats. If unsure a span is an IP address or not, tag `AMBIGUOUS` instead.\\n\\n### NAME\\n\\nA person\\'s name, including just first name or last name only. Do not include title used. For example, if \"Ms. Doe\" is used, please highlight \"Doe\" only.\\nFor now we are not tagging usernames.\\n\\n### PASSWORD\\n\\nAny authentication credentials not applicable to SSH keys or API keys. If unsure, tag `AMBIGUOUS`.\\n\\n### SSH_KEY\\nSecure Shell Key, the output usually looks like `ssh-rsa public_key account`, see example [here](https://git-scm.com/book/en/v2/Git-on-the-Server-Generating-Your-SSH-Public-Key). Please highlight the entire public key span. \\n\\n### USERNAME\\n\\nAny username that is used, including for credentials or handles (such as GitHub handles). If username is an email, tag `EMAIL` instead.\\n\\n## Additional note: Class CONTAINS_NON_ENGLISH\\n\\nIf you find a file with comments in a natural language you don\\'t undertsand and can\\'t decide if it includes PII, label it with the class `CONTAINS_NON_ENGLISH`.',\n",
       " 'schema_id': '33a5ef29-c22f-4e64-8fee-6019dde1c76d',\n",
       " 'dataset_id': '5ed27353-49a7-42e9-bc84-81e15f3f4162',\n",
       " 'project_id': '87c47b2c-d503-4967-b314-c04d1e7f8be7',\n",
       " 'created_at': '2022-11-03T17:18:13.282687Z',\n",
       " 'relationSchema_id': None,\n",
       " 'suggestion_models': ['7490d065-5329-4561-8cdb-71f3416033e2'],\n",
       " 'teams': ['9b13d981-9ade-4dd5-8bf2-886c9f11945d'],\n",
       " 'labels': [],\n",
       " 'hide_example_metadata': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_definitions = (session.get(API_BASE+'projects/default/task_definitions/').json())\n",
    "task_definitions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://bigcodepii.lighttag.io/api/v1/projects/default/task_definitions/pii-labeling-pre-filtered-data/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_td = task_definitions[1]['url'] # Get the url for the test set task definition\n",
    "test_td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = session.get(test_td+'download/').json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'examples', 'schema', 'dataset', 'relations', 'name', 'annotators_per_example'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data[\"examples\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['content', 'seen_by', 'comments', 'metadata', 'example_id', 'annotations', 'classifications'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total # reviewed annotations: 1318\n",
      "total # annotations: 1318\n"
     ]
    }
   ],
   "source": [
    "# verify that all annotations are reviewed\n",
    "count = 0\n",
    "for example in dataset:\n",
    "    for annotation in example[\"annotations\"]:\n",
    "        assert annotation[\"reviewed\"] == True\n",
    "        count += 1\n",
    "print(f\"total # reviewed annotations: {count}\")\n",
    "print(f\"total # annotations: {sum([len(ex['annotations']) for ex in dataset])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "for i, e in enumerate(dataset):\n",
    "    if e[\"example_id\"] == \"251926c8-f8cb-443f-99e0-77254d63430d\":\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'end': 33732,\n",
       "  'tag': 'PASSWORD',\n",
       "  'start': 33724,\n",
       "  'value': 'password',\n",
       "  'tag_id': 'd7945153-264b-42d8-8db8-e98fa49397a7',\n",
       "  'correct': True,\n",
       "  'reviewed': True,\n",
       "  'example_id': '251926c8-f8cb-443f-99e0-77254d63430d',\n",
       "  'annotated_by': [{'annotator': None,\n",
       "    'timestamp': None,\n",
       "    'annotator_id': None}],\n",
       "  'definition_id': 'a6e0c132-cd58-45d1-8dd5-5af8cdc6d399',\n",
       "  'tagged_token_id': '38e747c4-76f3-468e-a660-33c98f79c24a'},\n",
       " {'end': 33372,\n",
       "  'tag': 'PASSWORD',\n",
       "  'start': 33364,\n",
       "  'value': 'wrongpwd',\n",
       "  'tag_id': 'd7945153-264b-42d8-8db8-e98fa49397a7',\n",
       "  'correct': True,\n",
       "  'reviewed': True,\n",
       "  'example_id': '251926c8-f8cb-443f-99e0-77254d63430d',\n",
       "  'annotated_by': [{'annotator': 'shamik.bose89@gmail.com',\n",
       "    'timestamp': '2022-11-05T16:51:02.317+00:00',\n",
       "    'annotator_id': 10}],\n",
       "  'definition_id': 'a6e0c132-cd58-45d1-8dd5-5af8cdc6d399',\n",
       "  'tagged_token_id': 'ad3fcf9d-7c96-4db9-adf4-3c5e4852540e'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[i][\"annotations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'end': 20662, 'tag': 'USERNAME', 'start': 20654, 'value': 'rheineke', 'tag_id': 'c1f50281-3cff-4eee-85d4-212d99963238', 'correct': True, 'reviewed': True, 'example_id': '00f9b923-ab9d-4373-a6e0-d6172f7999fd', 'annotated_by': [{'annotator': 'christopher.akiki@gmail.com', 'timestamp': '2022-11-08T14:47:37.582428+00:00', 'annotator_id': 4}], 'definition_id': 'a6e0c132-cd58-45d1-8dd5-5af8cdc6d399', 'tagged_token_id': 'e0ad7e43-6233-4346-98b0-f72f9b6b35ea'}, {'end': 55, 'tag': 'EMAIL', 'start': 32, 'value': 'reece.heineke@gmail.com', 'tag_id': '76b4fbc7-b129-40ea-a6d3-8988fe626973', 'correct': True, 'reviewed': True, 'example_id': '00f9b923-ab9d-4373-a6e0-d6172f7999fd', 'annotated_by': [{'annotator': 'loubnabenallal1999@gmail.com', 'timestamp': '2022-11-05T17:58:17.881+00:00', 'annotator_id': 1}], 'definition_id': 'a6e0c132-cd58-45d1-8dd5-5af8cdc6d399', 'tagged_token_id': 'ad00e862-d92a-4cc0-92ea-a0e97b70f5f7'}, {'end': 31, 'tag': 'NAME', 'start': 18, 'value': 'Reece Heineke', 'tag_id': '555cc074-289d-40b7-8e11-6221bb7c7167', 'correct': True, 'reviewed': True, 'example_id': '00f9b923-ab9d-4373-a6e0-d6172f7999fd', 'annotated_by': [{'annotator': 'christopher.akiki@gmail.com', 'timestamp': '2022-11-07T09:38:24.735572+00:00', 'annotator_id': 4}, {'annotator': 'christopher.akiki@gmail.com', 'timestamp': '2022-11-08T15:12:14.564192+00:00', 'annotator_id': 4}], 'definition_id': 'a6e0c132-cd58-45d1-8dd5-5af8cdc6d399', 'tagged_token_id': '8c272f1a-554e-48ce-8bd5-8d96ea496293'}]\n",
      "\n",
      "\n",
      "[{'end': 20662, 'tag': 'AMBIGUOUS', 'start': 20654, 'value': 'rheineke', 'tag_id': '3687481c-bf1c-423e-bf1d-287d6a5c67e0', 'correct': False, 'reviewed': True, 'example_id': '00f9b923-ab9d-4373-a6e0-d6172f7999fd', 'annotated_by': [{'annotator': 'christopher.akiki@gmail.com', 'timestamp': '2022-11-08T14:47:30.185752+00:00', 'annotator_id': 4}], 'definition_id': 'a6e0c132-cd58-45d1-8dd5-5af8cdc6d399', 'tagged_token_id': '8dd1106f-75eb-4184-96d1-865f0e516e13'}, {'end': 30, 'tag': 'AMBIGUOUS', 'start': 17, 'value': ' Reece Heinek', 'tag_id': '3687481c-bf1c-423e-bf1d-287d6a5c67e0', 'correct': False, 'reviewed': True, 'example_id': '00f9b923-ab9d-4373-a6e0-d6172f7999fd', 'annotated_by': [{'annotator': 'christopher.akiki@gmail.com', 'timestamp': '2022-11-07T09:34:55.441427+00:00', 'annotator_id': 4}], 'definition_id': 'a6e0c132-cd58-45d1-8dd5-5af8cdc6d399', 'tagged_token_id': '5028a874-0c96-459d-9887-2ba6ca67dfc1'}, {'end': 31, 'tag': 'AMBIGUOUS', 'start': 18, 'value': 'Reece Heineke', 'tag_id': '3687481c-bf1c-423e-bf1d-287d6a5c67e0', 'correct': False, 'reviewed': True, 'example_id': '00f9b923-ab9d-4373-a6e0-d6172f7999fd', 'annotated_by': [{'annotator': 'christopher.akiki@gmail.com', 'timestamp': '2022-11-08T15:12:11.995254+00:00', 'annotator_id': 4}, {'annotator': 'christopher.akiki@gmail.com', 'timestamp': '2022-11-07T09:38:19.96111+00:00', 'annotator_id': 4}], 'definition_id': 'a6e0c132-cd58-45d1-8dd5-5af8cdc6d399', 'tagged_token_id': 'b1c1fcf5-529e-4503-a637-b6f74e47bf4c'}]\n"
     ]
    }
   ],
   "source": [
    "# example annotations: those rejected by reviewers are kept with the tag correct: False, let's remove them\n",
    "example = dataset[362]\n",
    "print([a for a in example[\"annotations\"] if a[\"correct\"]])\n",
    "print(\"\\n\")\n",
    "print([a for a in example[\"annotations\"] if not a[\"correct\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kept 1016 annotations, rejected 302 annotations\n"
     ]
    }
   ],
   "source": [
    "# remove annotations where \"correct\" is False\n",
    "rejected = 0\n",
    "kept = 0\n",
    "list_rejections = []\n",
    "for i, example in enumerate(dataset):\n",
    "    # only keep correct annotations (after review)\n",
    "    correct_annotations = [a for a in example[\"annotations\"] if a[\"correct\"]]\n",
    "    list_rejections += [a for a in example['annotations'] if not a['correct']]\n",
    "    #update dataset\n",
    "    dataset[i][\"annotations\"] = correct_annotations\n",
    "    \n",
    "print(f\"kept {sum([len(ex['annotations']) for ex in dataset])} annotations, rejected {len(list_rejections)} annotations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kept 1016 annotations, rejected 302 annotations\n"
     ]
    }
   ],
   "source": [
    "# remove annotations where \"correct\" is False\n",
    "rejected = 0\n",
    "kept = 0\n",
    "list_rejections = []\n",
    "for i, example in enumerate(dataset):\n",
    "    # only keep correct annotations (after review)\n",
    "    correct_annotations = [a for a in example[\"annotations\"] if a[\"correct\"]]\n",
    "    list_rejections += [a for a in example['annotations'] if not a['correct']]\n",
    "    #update dataset\n",
    "    dataset[i][\"annotations\"] = correct_annotations\n",
    "    \n",
    "print(f\"kept {sum([len(ex['annotations']) for ex in dataset])} annotations, rejected {len(list_rejections)} annotations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the dataset for `datasets` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datasets\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "def convert_key(example):\n",
    "    sample = deepcopy(example)\n",
    "    if sample[\"tag\"] in [\"API_KEY\", \"SSH_KEY\"]:\n",
    "        sample[\"tag\"] = \"KEY\"\n",
    "    return sample\n",
    "\n",
    "def process_example(example):\n",
    "    new_sample = {}\n",
    "    new_sample[\"content\"] = example[\"content\"]\n",
    "    new_sample[\"language\"] = example[\"metadata\"][\"lang\"]\n",
    "    new_sample[\"license\"] = example[\"metadata\"][\"licenses\"][0]\n",
    "    new_sample[\"path\"] = example[\"metadata\"][\"repository_name\"] + \"/\" + example[\"metadata\"][\"path\"]\n",
    "    new_sample[\"annotation_id\"] = example[\"example_id\"]\n",
    "    new_sample[\"pii\"] = []\n",
    "    new_sample[\"pii_modified\"] = []\n",
    "    for annotation in example[\"annotations\"]:\n",
    "        pii = {\"tag\": annotation[\"tag\"],\n",
    "                \"value\": annotation[\"value\"],\n",
    "                \"start\": annotation[\"start\"],\n",
    "                \"end\": annotation[\"end\"]}\n",
    "        start = max(0, pii[\"start\"] - 50)\n",
    "        end = min(len(new_sample[\"content\"]), pii[\"end\"] + 50)\n",
    "        pii[\"context\"] = new_sample[\"content\"][start:end]\n",
    "        # column with one Key tag for both API Keys and SSH keys\n",
    "        modified_pii = convert_key(pii)\n",
    "        new_sample[\"pii\"].append(pii)\n",
    "        new_sample[\"pii_modified\"].append(modified_pii)\n",
    "    # we save the pii in json to avoid not matching sizes per column in `datasets`\n",
    "    new_sample[\"pii\"] = json.dumps(new_sample[\"pii\"])\n",
    "    new_sample[\"pii_modified\"] = json.dumps(new_sample[\"pii_modified\"])\n",
    "    return new_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['content', 'language', 'license', 'path', 'annotation_id', 'pii', 'pii_modified'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'tag': 'API_KEY',\n",
       "  'value': '476611152863-ltgqfk9jhq1vsenin5039n58ogkraltb.apps.googleusercontent.com',\n",
       "  'start': 6842,\n",
       "  'end': 6914,\n",
       "  'context': 'onScheme;\\n\\n                   options.ClientId = \"476611152863-ltgqfk9jhq1vsenin5039n58ogkraltb.apps.googleusercontent.com\";\\n                   options.ClientSecret = \"rSHv'},\n",
       " {'tag': 'API_KEY',\n",
       "  'value': '99eb0b9d-ca40-476e-b5ac-6f4c32bfb530',\n",
       "  'start': 7336,\n",
       "  'end': 7372,\n",
       "  'context': ' false };\\n                    options.ClientId = \"99eb0b9d-ca40-476e-b5ac-6f4c32bfb530\";\\n                    options.CallbackPath = \"/si'},\n",
       " {'tag': 'USERNAME',\n",
       "  'value': 'aspnet',\n",
       "  'start': 7783,\n",
       "  'end': 7789,\n",
       "  'context': '         // And\\n            // https://github.com/aspnet/Docs/issues/2384#issuecomment-297980490\\n         '},\n",
       " {'tag': 'USERNAME',\n",
       "  'value': 'openiddict',\n",
       "  'start': 7692,\n",
       "  'end': 7702,\n",
       "  'context': ' env)\\n        {\\n            // https://github.com/openiddict/openiddict-core/issues/518\\n            // And\\n   '},\n",
       " {'tag': 'API_KEY',\n",
       "  'value': 'rSHvhgdOQUB4KMc5JS1alzhg',\n",
       "  'start': 6960,\n",
       "  'end': 6984,\n",
       "  'context': '.com\";\\n                   options.ClientSecret = \"rSHvhgdOQUB4KMc5JS1alzhg\";\\n               })\\n               .AddOpenIdConn'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# small test\n",
    "res = process_example(dataset[360])\n",
    "print(res.keys())\n",
    "pii = json.loads(res[\"pii\"])\n",
    "pii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tag': 'KEY',\n",
       "  'value': '476611152863-ltgqfk9jhq1vsenin5039n58ogkraltb.apps.googleusercontent.com',\n",
       "  'start': 6842,\n",
       "  'end': 6914,\n",
       "  'context': 'onScheme;\\n\\n                   options.ClientId = \"476611152863-ltgqfk9jhq1vsenin5039n58ogkraltb.apps.googleusercontent.com\";\\n                   options.ClientSecret = \"rSHv'},\n",
       " {'tag': 'KEY',\n",
       "  'value': '99eb0b9d-ca40-476e-b5ac-6f4c32bfb530',\n",
       "  'start': 7336,\n",
       "  'end': 7372,\n",
       "  'context': ' false };\\n                    options.ClientId = \"99eb0b9d-ca40-476e-b5ac-6f4c32bfb530\";\\n                    options.CallbackPath = \"/si'},\n",
       " {'tag': 'USERNAME',\n",
       "  'value': 'aspnet',\n",
       "  'start': 7783,\n",
       "  'end': 7789,\n",
       "  'context': '         // And\\n            // https://github.com/aspnet/Docs/issues/2384#issuecomment-297980490\\n         '},\n",
       " {'tag': 'USERNAME',\n",
       "  'value': 'openiddict',\n",
       "  'start': 7692,\n",
       "  'end': 7702,\n",
       "  'context': ' env)\\n        {\\n            // https://github.com/openiddict/openiddict-core/issues/518\\n            // And\\n   '},\n",
       " {'tag': 'KEY',\n",
       "  'value': 'rSHvhgdOQUB4KMc5JS1alzhg',\n",
       "  'start': 6960,\n",
       "  'end': 6984,\n",
       "  'context': '.com\";\\n                   options.ClientSecret = \"rSHvhgdOQUB4KMc5JS1alzhg\";\\n               })\\n               .AddOpenIdConn'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pii = json.loads(res[\"pii_modified\"])\n",
    "pii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a dataset\n",
    "def build_dataset(data):\n",
    "    df = pd.DataFrame([process_example(ex) for ex in data])\n",
    "    dataset = datasets.Dataset.from_pandas(df)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset = build_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['content', 'language', 'license', 'path', 'annotation_id', 'pii', 'pii_modified'],\n",
       "    num_rows: 400\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b22d4ed13d496d9bec51876d270837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3861956"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset.to_json(\"prefiltered_v2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['content', 'language', 'license', 'path', 'annotation_id', 'pii', 'pii_modified'],\n",
       "    num_rows: 400\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual reviewing of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i += 1\n",
    "pii = json.loads(hf_dataset[i][\"pii\"])\n",
    "for annot in pii:\n",
    "    print(i, annot[\"tag\"], annot[\"value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* example 34 has a wrong password, example 158 has a wrong IP address, 206 has a wrong passwor and 241 has many API keys that don't look like tokens and are propably passwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['content', 'language', 'license', 'path', 'annotation_id', 'pii', 'pii_modified', 'id'],\n",
       "    num_rows: 400\n",
       "})"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add id column to dataset as a new column\n",
    "hf_dataset = hf_dataset.add_column(\"id\", [i for i in range(len(hf_dataset))])\n",
    "hf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_pii(example):\n",
    "    new_example = deepcopy(example)\n",
    "    if example[\"id\"] in [34, 206]:\n",
    "        pii = json.loads(example[\"pii\"])\n",
    "        # remove wrong password\n",
    "        new_example[\"pii\"] = json.dumps(pii[1:])\n",
    "        new_example[\"pii_modified\"] = json.dumps(pii[1:])\n",
    "\n",
    "    elif example[\"id\"] == 158:\n",
    "        pii = json.loads(hf_dataset[158][\"pii\"])\n",
    "        # remove wrong IP_ADDRESS\n",
    "        pii = pii[:3] + pii[4:]\n",
    "        new_example[\"pii\"] = json.dumps(pii)\n",
    "        new_example[\"pii_modified\"] = json.dumps(pii)\n",
    "\n",
    "    elif example[\"id\"] == 241:\n",
    "        pii = json.loads(example[\"pii\"])\n",
    "        for id, e in enumerate(pii):\n",
    "            if e[\"value\"] == \"AIzaasdf\":\n",
    "                pii[id][\"tag\"] = \"PASSWORD\"\n",
    "        new_example[\"pii\"] = json.dumps(pii)\n",
    "        new_example[\"pii_modified\"] = json.dumps(pii)\n",
    "    return new_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2cc34b78afa480c8e8149150e00913c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_dataset_2 = hf_dataset.map(update_pii, features=hf_dataset.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset_2 = hf_dataset_2.remove_columns([\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['content', 'language', 'license', 'path', 'annotation_id', 'pii', 'pii_modified'],\n",
       "    num_rows: 400\n",
       "})"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 PASSWORD wrongpwd\n"
     ]
    }
   ],
   "source": [
    "id = 34\n",
    "pii = json.loads(hf_dataset_2[id][\"pii\"])\n",
    "for annot in pii:\n",
    "    print(id, annot[\"tag\"], annot[\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove file at index 11 many ambigous keys\n",
    "# remove file 51 many incorrect names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'indices'=<generator object <genexpr> at 0x7fd6c1dd8430> of the transform datasets.arrow_dataset.Dataset.select couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    }
   ],
   "source": [
    "hf_dataset_3 = hf_dataset_2.select((i for i in range(len(hf_dataset_2)) if i!=11 and i!=51))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples kept: 224\n"
     ]
    }
   ],
   "source": [
    "with open('data_lightag/pii-first-final.json') as f:\n",
    "    labels_no_filter = json.load(f)\n",
    "\n",
    "def build_dataset_n(labels):\n",
    "    examples = labels[\"examples\"]\n",
    "    df = pd.DataFrame([process_example(ex) for ex in examples])\n",
    "    dataset = datasets.Dataset.from_pandas(df)\n",
    "    return dataset\n",
    "\n",
    "# remove examples where seen_by is empty\n",
    "L = []\n",
    "for example in labels_no_filter[\"examples\"]:\n",
    "    if example[\"seen_by\"]:\n",
    "        L.append(example)\n",
    "labels_no_filter[\"examples\"] = L\n",
    "print(f\"# samples kept: {len(labels_no_filter['examples'])}\")\n",
    "\n",
    "dataset_no_filter = build_dataset_n(labels_no_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['content', 'language', 'license', 'path', 'annotation_id', 'pii', 'pii_modified'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_samples = dataset_no_filter.select([223, 218])\n",
    "two_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['content', 'language', 'license', 'path', 'annotation_id', 'pii', 'pii_modified'],\n",
       "    num_rows: 400\n",
       "})"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_clean = datasets.concatenate_datasets([hf_dataset_3, two_samples])\n",
    "ds_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f1c33ee2bb48c28eb368dcbfbe6eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3724333"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_clean.to_json(\"prefiltered_final.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c14a9610ffc4f528b3fd393a3e2aea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_clean.push_to_hub(\"dummy_data_clean\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd8fde6f83dada9276d12fdb71d773558994168ed1b3bea457b8db38c02aa2e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
